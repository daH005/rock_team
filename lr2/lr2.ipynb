{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e66e7f92-a5d9-4613-bd57-1b58c999328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeppavlov in ./venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: fastapi<=0.89.1,>=0.47.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (0.89.1)\n",
      "Requirement already satisfied: filelock<3.10.0,>=3.0.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (3.9.1)\n",
      "Requirement already satisfied: nltk<3.10.0,>=3.2.4 in ./venv/lib/python3.10/site-packages (from deeppavlov) (3.9.1)\n",
      "Requirement already satisfied: numpy<1.24 in ./venv/lib/python3.10/site-packages (from deeppavlov) (1.23.5)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (1.5.3)\n",
      "Requirement already satisfied: prometheus-client<=1.16.0,>=0.13.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (0.21.1)\n",
      "Requirement already satisfied: pydantic<2 in ./venv/lib/python3.10/site-packages (from deeppavlov) (1.10.21)\n",
      "Requirement already satisfied: pybind11==2.10.3 in ./venv/lib/python3.10/site-packages (from deeppavlov) (2.10.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (2.32.3)\n",
      "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (4.64.1)\n",
      "Requirement already satisfied: uvicorn<0.19.0,>=0.13.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (0.18.3)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from deeppavlov) (0.45.1)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.24 in ./venv/lib/python3.10/site-packages (from deeppavlov) (1.0.2)\n",
      "Requirement already satisfied: scipy==1.10.0 in ./venv/lib/python3.10/site-packages (from deeppavlov) (1.10.0)\n",
      "Requirement already satisfied: starlette==0.22.0 in ./venv/lib/python3.10/site-packages (from fastapi<=0.89.1,>=0.47.0->deeppavlov) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in ./venv/lib/python3.10/site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (4.8.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.10/site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.10/site-packages (from pydantic<2->deeppavlov) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov) (3.5.0)\n",
      "Requirement already satisfied: h11>=0.8 in ./venv/lib/python3.10/site-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.0.0->deeppavlov) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ec9c26f-d42b-4972-88be-804e97c39fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d9e513eff02970bbdb9f3ef71f2d7321b056a3432565de1245b323c931eb0a53\n",
      "  Stored in directory: /home/dan005/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "043a1506-0b23-4f89-8050-20d239cce670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dan005/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from deeppavlov import build_model\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1955f8b-4848-4896-8379-e5589aeb0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./toxic_comments.csv', \n",
    "    engine='python', \n",
    "    on_bad_lines='skip',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dec41f-c693-4e57-a1c9-809b84dc0c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3260bec-c685-4161-bd8f-0c53559f2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ea4ae-c267-4ffb-8fdb-4ec9cd80cf17",
   "metadata": {},
   "source": [
    "–ß—Ç–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ + —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99724ff2-3230-499c-93ec-1967a29c39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b4982aa-3301-4701-a302-796526cdd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_and_lemmatize_series(series: pd.Series) -> pd.Series:\n",
    "    return series.apply(_clear_and_lemmatize_text)\n",
    "\n",
    "\n",
    "def _clear_and_lemmatize_text(text: str) -> str:\n",
    "    return _clear_text(_lemmatize_text(text))\n",
    "    \n",
    "\n",
    "def _clear_text(text: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "\n",
    "def _lemmatize_text(text: str) -> str:\n",
    "    return ' '.join(lemmatizer.parse(word)[0].normal_form for word in text.lower().split())\n",
    "\n",
    "\n",
    "def vectorize_series(series: pd.Series) -> list[str]:\n",
    "    return list(vectorizer.fit_transform(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbddc01c-db21-42f1-8f04-f7864dbe6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prepared_text'] = clear_and_lemmatize_series(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f976aacf-1806-4429-abd5-01b72a9d6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectorized_text'] = vectorize_series(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ab601-07e9-41bf-bf1e-ad960d1f9067",
   "metadata": {},
   "source": [
    "–í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤ + –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é.\n",
    "–¢–∞–∫–∂–µ –º—ã —Å–¥–µ–ª–∞–ª–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–æ–≤, –Ω–æ –¥–∞–ª—å—à–µ –æ–Ω–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ —É–∂–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ `deeppavlov.build_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "554f3b3c-caff-4875-b13a-48fbd9e1535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>prepared_text</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>(0, 3446)\\t0.16769576946881884\\n  (0, 4373)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww  he match this background colour i m see...</td>\n",
       "      <td>(0, 142295)\\t0.16412463608924402\\n  (0, 2613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>(0, 69411)\\t0.20448767581830993\\n  (0, 8935)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on imp...</td>\n",
       "      <td>(0, 137467)\\t0.16225009518550423\\n  (0, 5929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>(0, 146787)\\t0.18634179087764524\\n  (0, 1136...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                       prepared_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d aww  he match this background colour i m see...   \n",
       "2  hey man  i m really not trying to edit war  it...   \n",
       "3    more i can t make any real suggestion on imp...   \n",
       "4  you  sir  are my hero  any chance you remember...   \n",
       "\n",
       "                                     vectorized_text  \n",
       "0    (0, 3446)\\t0.16769576946881884\\n  (0, 4373)\\...  \n",
       "1    (0, 142295)\\t0.16412463608924402\\n  (0, 2613...  \n",
       "2    (0, 69411)\\t0.20448767581830993\\n  (0, 8935)...  \n",
       "3    (0, 137467)\\t0.16225009518550423\\n  (0, 5929...  \n",
       "4    (0, 146787)\\t0.18634179087764524\\n  (0, 1136...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95743595-1438-4b75-a2d1-62cdc30efa2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch<1.14.0,>=1.6.0 in ./venv/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (75.6.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (0.45.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring transformers: markers 'python_version < \"3.8\"' don't match your environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.30.0 in ./venv/lib/python3.10/site-packages (4.30.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "2025-02-08 04:49:39.391 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/datasets/insults_data.tar.gz download because of matching hashes\n",
      "2025-02-08 04:49:42.331 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/insults_kaggle_torch_bert_v5.tar.gz download because of matching hashes\n",
      "/home/dan005/rock_team/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-02-08 04:49:44.23 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "model = build_model('insults_kaggle_bert', download=True, install=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02620eb3-327c-4263-89c0-e023f8f366b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = model(df['prepared_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae03fd-c1de-4e2d-810f-207e1825db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_result_series(series):\n",
    "    series = series.str.replace('Not Insult', '0').str.replace('Insult', '1').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93b6f6-f084-4a3b-bb16-bbc7a81df0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = unify_result_series(df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11188385-5601-47f3-af3f-d0b0a9f35e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['result'] == df['toxic']).sum() / len(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5494215f-b6b0-4023-bb85-1d275380bc9f",
   "metadata": {},
   "source": [
    "–ú—ã —Å–æ–∑–¥–∞–ª–∏ –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –≤ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö.\n",
    "–í –∫–æ–Ω—Ü–µ –º—ã –≤—ã—á–∏—Å–ª–∏–ª–∏ –¥–æ–ª—é –≤–µ—Ä–Ω–æ —É–≥–∞–¥–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–∏.\n",
    "–î–∞–ª–µ–µ –º—ã –ø—Ä–æ–¥–µ–ª–∞–µ–º –≤—Å—ë —Ç–æ–∂–µ —Å–∞–º–æ–µ, –Ω–æ —Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf626c-a839-402e-a1e4-295d45cb4b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e45e1e6b-c859-4b22-bcf3-3e681c341771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./rusentitweet_full.csv', \n",
    "    engine='python', \n",
    "    on_bad_lines='skip',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "493e0117-b2ad-45e1-8809-d8101caab569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@varlamov @McFaul –ù–∞</td>\n",
       "      <td>skip</td>\n",
       "      <td>1327934765807308801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1252943181387350017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1323610669061677056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1336231661160247297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1292421736454127617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text     label  \\\n",
       "0           0                               @varlamov @McFaul –ù–∞      skip   \n",
       "1           1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "2           2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "3           3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "4           4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "\n",
       "                    id  \n",
       "0  1327934765807308801  \n",
       "1  1252943181387350017  \n",
       "2  1323610669061677056  \n",
       "3  1336231661160247297  \n",
       "4  1292421736454127617  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5470ebac-0620-4450-87c0-f5dd77acb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "538bfe9f-2107-48f6-9f8d-6d8f99a3919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6cc2264-ef5c-4477-8198-e2be21bacafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].str.replace('skip', '0').str.replace('neutral', '0').str.replace('speech', '0').str.replace('positive', '0').str.replace('negative', '1').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a12b3e4e-eaab-4e67-b7e6-c7655dde95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prepared_text'] = clear_and_lemmatize_series(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb3b28fe-65eb-486f-a134-2ec8e46caf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectorized_text'] = vectorize_series(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "408ec919-935e-41cc-a33d-95e4bc8361de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prepared_text</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@varlamov @McFaul –ù–∞</td>\n",
       "      <td>0</td>\n",
       "      <td>varlamov  mcfaul –Ω–∞</td>\n",
       "      <td>(0, 23468)\\t0.2461112602099971\\n  (0, 6947)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª–∞ –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>(0, 33023)\\t0.3948292135261448\\n  (0, 24491)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>1</td>\n",
       "      <td>—Ç—Ä–µ–∑–≤—ã–π –∂–∏–∑–Ω—å –∫–∞–∫–æ–π —Ç–æ —Ç–∞–∫–æ–π —Å—Ç—Ä—ë–º–Ω–∞—è   —Å  –∞—Ä...</td>\n",
       "      <td>(0, 2020)\\t0.43475956880519917\\n  (0, 12903)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>–æ–π –∫–∞–∫–æ–π –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç   https   t co ...</td>\n",
       "      <td>(0, 12249)\\t0.5238290833865648\\n  (0, 2828)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>shvonder_chief  dimsmirnov175 –Ω–∞ –∑–∞–±–æ—Ä —Ç–æ–∂–µ –Ω...</td>\n",
       "      <td>(0, 15296)\\t0.2777613868475538\\n  (0, 31878)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0                               @varlamov @McFaul –ù–∞      0   \n",
       "1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...      1   \n",
       "2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...      1   \n",
       "3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...      0   \n",
       "4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...      0   \n",
       "\n",
       "                                       prepared_text  \\\n",
       "0                                varlamov  mcfaul –Ω–∞   \n",
       "1  –≤–µ–ª–ª–∞ –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...   \n",
       "2   —Ç—Ä–µ–∑–≤—ã–π –∂–∏–∑–Ω—å –∫–∞–∫–æ–π —Ç–æ —Ç–∞–∫–æ–π —Å—Ç—Ä—ë–º–Ω–∞—è   —Å  –∞—Ä...   \n",
       "3  –æ–π –∫–∞–∫–æ–π –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç   https   t co ...   \n",
       "4   shvonder_chief  dimsmirnov175 –Ω–∞ –∑–∞–±–æ—Ä —Ç–æ–∂–µ –Ω...   \n",
       "\n",
       "                                     vectorized_text  \n",
       "0    (0, 23468)\\t0.2461112602099971\\n  (0, 6947)\\...  \n",
       "1    (0, 33023)\\t0.3948292135261448\\n  (0, 24491)...  \n",
       "2    (0, 2020)\\t0.43475956880519917\\n  (0, 12903)...  \n",
       "3    (0, 12249)\\t0.5238290833865648\\n  (0, 2828)\\...  \n",
       "4    (0, 15296)\\t0.2777613868475538\\n  (0, 31878)...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa46e26f-3914-4982-9918-d597bbad5aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch<1.14.0,>=1.6.0 in ./venv/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (75.6.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (0.45.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring transformers: markers 'python_version < \"3.8\"' don't match your environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.30.0 in ./venv/lib/python3.10/site-packages (4.30.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "2025-02-08 05:14:20.998 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/v1/classifiers/rusentiment_convers_bert/rusentiment_convers_bert_torch.tar.gz to /home/dan005/.deeppavlov/models/classifiers/rusentiment_convers_bert_torch.tar.gz\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.52G/1.52G [02:16<00:00, 11.1MB/s]\n",
      "2025-02-08 05:16:38.112 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting /home/dan005/.deeppavlov/models/classifiers/rusentiment_convers_bert_torch.tar.gz archive into /home/dan005/.deeppavlov/models/classifiers/rusentiment_convers_bert_torch\n",
      "/home/dan005/rock_team/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3423d69609f47e0bce9a2f5f2e5ae8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477e5a0ded1b4d2e8fc4542be6a940bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21479ebf1a4f86b809cad2728b0edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fff4752bf84c47ada0e7c165fc1629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99056033bd93490e957894081cefe0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-02-08 05:18:11.355 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "model = build_model('rusentiment_convers_bert', download=True, install=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4a14c-7e93-4afb-85b5-2ee280f1468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = model(df['prepared_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2531d-5772-4f40-b046-7212a9ebec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = unify_result_series(df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456ce6b-55a9-4a87-b447-7cc25e3f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['result'] == df['label']).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598b9ad-8e58-4906-9851-8cf9b46853a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60be85-7f91-4e9e-9888-0d9a584f9cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
