{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24d3fc7-b458-4678-8e99-679b3ab533f8",
   "metadata": {},
   "source": [
    "В этой работе мы реализуем переводчик с русского языка на язык Старшей Речи и наоборот. Тоже самое с английским.\n",
    "Мы реализуем алгоритм для перевода с русского на Старшую Речь.\n",
    "Далее используем его для формирования примерно 200 эталонных переводов, на основе которых будем оценивать качество переводов следующих моделей:\n",
    "1. Llama\n",
    "2. Deepseek\n",
    "3. Gemma\n",
    "\n",
    "Перед началом переводов каждая модель будет настроена промптами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab7e4b1-0108-40b1-901b-940fb9fb1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "import pymorphy2\n",
    "lemmer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import ollama\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b4a420-c9a7-4fba-a953-c306550bd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../lr3/witcher_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b054f-52a3-4884-9a9b-b73d1c74bce8",
   "metadata": {},
   "source": [
    "Напишем прямой алгоритм перевода с русского на Старшую Речь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f271ebd5-0728-4dfd-9f5f-0e5a102c3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_russian_to_elvish(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Переводит русский текст на язык Старшей Речи.\n",
    "    Слова, перевод которым подобрать не получилось, латинизируются.\n",
    "    Присутствует обработка некоторых устойчивых выражений из словаря.\n",
    "    \"\"\"\n",
    "\n",
    "    # Унифицируем е/ё:\n",
    "    text = text.replace('ё', 'е')\n",
    "\n",
    "    # Результирующие подстроки для склеивания в конце.\n",
    "    result_subs = []\n",
    "\n",
    "    # Отделяем слова от пунктуационных знаков:\n",
    "    subs = re.split(r'(?<=\\.|!|\\?|,|;|:|\\s|\\n|\\(|\\))|(?=\\.|!|\\?|,|;|:|\\s|\\n|\\(|\\))', text)\n",
    "\n",
    "    next_i = 0\n",
    "    for i, sub in enumerate(subs):\n",
    "        if i < next_i:\n",
    "            continue\n",
    "\n",
    "        next_i += 1\n",
    "        if sub in string.punctuation + ' \\n':\n",
    "            result_subs.append(sub)\n",
    "            continue\n",
    "\n",
    "        word = sub\n",
    "        is_title = word.replace('\\'', '').istitle()\n",
    "        word = word.lower()\n",
    "        word = _word_to_lemm(word)\n",
    "\n",
    "        # Текущее слово может быть началом какого-то устойчивого выражения, проверим это.\n",
    "        it_is_real_phrase = False\n",
    "        phrases = _find_phrases_that_starts_with_russian_word(word)\n",
    "        if phrases and i != len(subs) - 1:\n",
    "            # Будем прибавлять сюда последующие пробелы и слова, пока не встретим что-то лишнее либо не убедимся\n",
    "            # в том, что это выражение - действительная устойчивая фраза из словаря.\n",
    "            summ_word = word\n",
    "\n",
    "            # Количество итераций для пропуска во внешнем цикле (через `next_i`)\n",
    "            count_to_pass = 0\n",
    "\n",
    "            for sub in subs[i + 1:]:\n",
    "                if sub in '.!?':\n",
    "                    break\n",
    "\n",
    "                count_to_pass += 1\n",
    "                if sub not in string.punctuation + ' ':\n",
    "                    sub = _word_to_lemm(sub.lower())\n",
    "                elif sub == ',':\n",
    "                    # Опускаем запятые между словами потенциальной фразы.\n",
    "                    sub = ''\n",
    "\n",
    "                summ_word += sub\n",
    "\n",
    "                need_continue = False\n",
    "                if summ_word in phrases:\n",
    "                    it_is_real_phrase = True\n",
    "                    break\n",
    "\n",
    "                for phrase in phrases:\n",
    "                    if summ_word in phrase:\n",
    "                        need_continue = True\n",
    "                        break\n",
    "\n",
    "                if not need_continue:\n",
    "                    break\n",
    "\n",
    "            if it_is_real_phrase:\n",
    "                word = summ_word\n",
    "                next_i += count_to_pass\n",
    "                translation = _try_to_find_russian_word_translation(word)\n",
    "\n",
    "        if not it_is_real_phrase:\n",
    "            # Стандартная обработка одиночного слова с подбором синонимов через сайт.\n",
    "            translation = None\n",
    "            try:\n",
    "                translation = _try_to_find_russian_word_translation(word)\n",
    "            except ValueError:\n",
    "                for synonym in _synonyms_of_word(word):\n",
    "                    try:\n",
    "                        translation = _try_to_find_russian_word_translation(synonym)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "            if translation is None:\n",
    "                translation = _transliterate_russian_to_latin(word)\n",
    "\n",
    "        if is_title:\n",
    "            translation = translation.capitalize()\n",
    "\n",
    "        result_subs.append(translation)\n",
    "\n",
    "    return ''.join(result_subs)\n",
    "\n",
    "\n",
    "def _word_to_lemm(word: str) -> str:\n",
    "    \"\"\"Переводит слово/словосочетание в начальную форму.\"\"\"\n",
    "    parts = []\n",
    "    for part in word.split():\n",
    "        part = lemmer.parse(part)[0].normal_form.replace('ё', 'е')\n",
    "        parts.append(part)\n",
    "\n",
    "    return ' '.join(parts)\n",
    "\n",
    "\n",
    "def _try_to_find_russian_word_translation(word: str) -> str:\n",
    "    \"\"\"Ищет перевод русского слова/словосочетания в датасете.\"\"\"\n",
    "    result = df.loc[df['translation'] == word, 'text']\n",
    "    if not result.empty:\n",
    "        return result.values[0]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def _find_phrases_that_starts_with_russian_word(word: str) -> list[str]:\n",
    "    return df.loc[df['translation'].str.startswith(word) & df['translation'].str.contains(' '), 'translation'].tolist()\n",
    "\n",
    "\n",
    "def _synonyms_of_word(word: str) -> str:\n",
    "    \"\"\"Выдаёт всевозможные синонимы заданного слова. Использует сетевой запрос.\"\"\"\n",
    "    html = requests.get(f'https://text.ru/synonym/{word}').text\n",
    "    \n",
    "    match = re.search(r'<meta name=\\\"description\\\" content=\\\"Синонимы к слову [^—]*:([^\\\"]+)\\\" />', html)\n",
    "    if match is None:\n",
    "        return []\n",
    "\n",
    "    text = match.group(1)\n",
    "    synonyms = [synonym.strip() for synonym in text.strip().split('—')]\n",
    "    synonyms.remove('')\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "\n",
    "def _transliterate_russian_to_latin(russian_word: str) -> str:\n",
    "    \"\"\"Функция для латинизации русского слова.\"\"\"\n",
    "    translit_dict = {\n",
    "        'а': 'a', \n",
    "        'б': 'b', \n",
    "        'в': 'v', \n",
    "        'г': 'g', \n",
    "        'д': 'd', \n",
    "        'е': 'e', \n",
    "        'ё': 'yo',\n",
    "        'ж': 'zh', \n",
    "        'з': 'z', \n",
    "        'и': 'i', \n",
    "        'й': 'y', \n",
    "        'к': 'k', \n",
    "        'л': 'l', \n",
    "        'м': 'm',\n",
    "        'н': 'n', \n",
    "        'о': 'o', \n",
    "        'п': 'p', \n",
    "        'р': 'r', \n",
    "        'с': 's', \n",
    "        'т': 't', \n",
    "        'у': 'u',\n",
    "        'ф': 'f', \n",
    "        'х': 'kh', \n",
    "        'ц': 'ts', \n",
    "        'ч': 'ch', \n",
    "        'ш': 'sh', \n",
    "        'щ': 'shch', \n",
    "        'ъ': '',\n",
    "        'ы': 'y', \n",
    "        'ь': '', \n",
    "        'э': 'e', \n",
    "        'ю': 'yu', \n",
    "        'я': 'ya',\n",
    "    }\n",
    "\n",
    "    latin_word = ''.join(translit_dict.get(symbol, symbol) for symbol in russian_word.lower())\n",
    "    return latin_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b31f1-6b56-495c-8b41-419376cfdf4d",
   "metadata": {},
   "source": [
    "Посмотрим пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c6531b-60ec-4667-a1d3-be3311753b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cead, Geralt Gwynbleidd! Do prisutstvie - bolshiy aere а evellienn sinn.\n"
     ]
    }
   ],
   "source": [
    "print(translate_russian_to_elvish('Здравствуй, Геральт Белый Волк! Твоё присутствие - большая честь для всех нас.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94549c-4c3c-4402-be8e-dce8d18c1cb2",
   "metadata": {},
   "source": [
    "Сформируем списки эталонных переводов. Запускать следующую ячейку, если файла \"backup.json\" нет. Если есть, то вторую, после неё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba5ea00b-d766-46c4-8c7e-8d83086fb5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "with open('./sequences.txt', 'r', encoding='utf-8') as f:\n",
    "    i = 0\n",
    "    for record in f:\n",
    "        record = record.strip()\n",
    "        if not record:\n",
    "            continue\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            # Записываем русское предложение + перевод.\n",
    "            sequences.append([\n",
    "                record,\n",
    "                translate_russian_to_elvish(record),\n",
    "            ])\n",
    "        else:\n",
    "            # Дозаписываем соответствующее английское предложение.\n",
    "            sequences[-1].append(record)\n",
    "\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            print('Часть записей обработана.')\n",
    "\n",
    "# Сохраняем эталонные переводы, чтобы не проводить эту процедуру каждый раз.\n",
    "with open('backup.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sequences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5fb5db-639b-41d9-a1df-e33782a84141",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backup.json', 'r', encoding='utf-8') as f:\n",
    "    sequences = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704df4e-4bbf-42d1-b1c9-b2dd56853362",
   "metadata": {},
   "source": [
    "Рассмотрим модели LLM для решения задачи перевода. Напишем общий класс для всех наших моделей из Olama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6e3873-ca3d-4d71-96ba-255d87dc8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    \"\"\"Обёртка над моделью LLM из Olama для реализации перевода.\"\"\"\n",
    "\n",
    "    _ONE_REQUEST_RECORD_COUNT = 100\n",
    "\n",
    "    def __init__(self, name: str) -> None:\n",
    "        self._name = name\n",
    "        self._context_messages = []\n",
    "\n",
    "    def init(self) -> None:\n",
    "        \"\"\"Подаёт на вход модели порционно все слова из словаря, после чего можно пользоваться методом `translate`.\"\"\"\n",
    "\n",
    "        print('Начало инициализации.')\n",
    "        self._request('Сейчас я буду отправлять тебе порциями слова на языке Старшей Речи и переводы на русский из словаря. '\n",
    "                      'Тебе нужно просто запоминать их и отвечать \"ok\". Потом я отправлю тебе \"go\" - это означает, что словарь кончился. '\n",
    "                      'Потом ты сможешь переводить с русского/английского на Старшую Речь и наоборот. '\n",
    "                      'Если слова нет в словаре, то попробуй подобрать по синониму или самое подходящее по смыслу. '\n",
    "                      'В самом худшем случае - латинизируй текст.')\n",
    "\n",
    "        portion = ''\n",
    "        for record in df.itertuples():\n",
    "            portion += f'{record[1]} - {record[2]}\\n'\n",
    "            if record[0] % self._ONE_REQUEST_RECORD_COUNT == 0 or record[0] == len(df) - 1:\n",
    "                print('Новый шаг инициализации...')\n",
    "                self._request(portion)\n",
    "                portion = ''\n",
    "\n",
    "        self._request('go')\n",
    "        print('Инициализация завершена.')\n",
    "\n",
    "    def translate_russian_to_elvish(self, text: str) -> str:\n",
    "        \"\"\"Переводит русский текст на Старшую Речь.\"\"\"\n",
    "        return self._request(f'Переведи русский текст \"{text}\" на Старшую Речь согласно словарю. Напиши только перевод.')\n",
    "\n",
    "    def translate_elvish_to_russian(self, text: str) -> str:\n",
    "        \"\"\"Переводит текст на языке Старшей Речи на русский.\"\"\"\n",
    "        return self._request(f'Переведи текст на языке Старшей Речи \"{text}\" на русский согласно словарю. Напиши только перевод.')\n",
    "\n",
    "    def translate_english_to_elvish(self, text: str) -> str:\n",
    "        \"\"\"Переводит английский текст на Старшую Речь.\"\"\"\n",
    "        text = self._request(f'Переведи английский текст \"{text}\" на русский. Напиши только перевод.')\n",
    "        return self.translate_russian_to_elvish(text)\n",
    "\n",
    "    def translate_elvish_to_english(self, text: str) -> str:\n",
    "        \"\"\"Переводит текст на языке Старшей Речи на английский.\"\"\"\n",
    "        text = self.translate_elvish_to_russian(text)\n",
    "        return self._request(f'Переведи русский текст \"{text}\" на английский. Напиши только перевод.')\n",
    "\n",
    "    def _request(self, text: str) -> str:\n",
    "        \"\"\"Отправляет запрос модели и выдает ответ.\"\"\"\n",
    "        self._context_messages.append({\n",
    "            'role': 'user', \n",
    "            'content': text,\n",
    "        })\n",
    "        answer = ollama.chat(model=self._name, messages=self._context_messages)['message']['content']\n",
    "        if '</think>' in answer:\n",
    "            answer = answer.split('</think>')[1]\n",
    "\n",
    "        return answer.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f8d2b1-867d-4730-be38-12c7689b4736",
   "metadata": {},
   "source": [
    "Начнем тестировать наши модели. Используем метрику BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13494e7-b2c9-42d3-90c8-c12718439b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n",
      "Начало инициализации.\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Инициализация завершена.\n",
      "Russian-To-Elvish Score: 1.5027054919908146e-231\n",
      "Elvish-To-Russian Score: 1.5469438467590993e-231\n",
      "English-To-Elvish Score: 1.489018608388989e-231\n",
      "Elvish-To-English Score: 1.4810351790853938e-231\n",
      "deepseek-r1\n",
      "Начало инициализации.\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Инициализация завершена.\n",
      "Russian-To-Elvish Score: 1.4528078000449406e-231\n",
      "Elvish-To-Russian Score: 1.4497066745242832e-231\n",
      "English-To-Elvish Score: 1.3641065241088982e-231\n",
      "Elvish-To-English Score: 1.459533643573846e-231\n",
      "gemma3\n",
      "Начало инициализации.\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n",
      "Новый шаг инициализации...\n"
     ]
    }
   ],
   "source": [
    "for model_name in ('llama3', 'deepseek-r1', 'gemma3'):\n",
    "    print(model_name)\n",
    "\n",
    "    translator = Translator(model_name)\n",
    "    translator.init()\n",
    "\n",
    "    bleu_scores_russian_to_elvish = []\n",
    "    bleu_scores_elvish_to_russian = []\n",
    "\n",
    "    bleu_scores_english_to_elvish = []\n",
    "    bleu_scores_elvish_to_english = []\n",
    "\n",
    "    for i, record in enumerate(sequences[:5], start=1):\n",
    "        if i % 50 == 0:\n",
    "            print('Часть записей обработана.')\n",
    "\n",
    "        bleu_scores_russian_to_elvish.append(\n",
    "            sentence_bleu(\n",
    "                translator.translate_russian_to_elvish(record[0]), \n",
    "                record[1],\n",
    "            )\n",
    "        )\n",
    "        bleu_scores_elvish_to_russian.append(\n",
    "            sentence_bleu(\n",
    "                translator.translate_elvish_to_russian(record[1]), \n",
    "                record[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        bleu_scores_english_to_elvish.append(\n",
    "            sentence_bleu(\n",
    "                translator.translate_english_to_elvish(record[2]), \n",
    "                record[1],\n",
    "            )\n",
    "        )\n",
    "        bleu_scores_elvish_to_english.append(\n",
    "            sentence_bleu(\n",
    "                translator.translate_elvish_to_english(record[1]), \n",
    "                record[2],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    score = sum(bleu_scores_russian_to_elvish) / len(bleu_scores_russian_to_elvish)\n",
    "    print('Russian-To-Elvish Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_elvish_to_russian) / len(bleu_scores_elvish_to_russian)\n",
    "    print('Elvish-To-Russian Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_english_to_elvish) / len(bleu_scores_english_to_elvish)\n",
    "    print('English-To-Elvish Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_elvish_to_english) / len(bleu_scores_elvish_to_english)\n",
    "    print('Elvish-To-English Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8bac93-780c-4afe-a8a2-5317107b4e49",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "В связи с тем, что мы работали на недостаточно мощном ПК, мы решили поставить всего 5 предложений на каждую модель (хотелось 200, как писалось изначально, но даже с 5-ю обработка шла очень долго).\n",
    "Метрики крайне маленькие. Отдельно мы проверили работу моделей и увидели, что они начинают путаться и выдают очень кривые ответы.\n",
    "Последняя модель - gemma3 застопорилась на этапе \"инициализации\", дальше мы не смогли её протестить.\n",
    "Ещё одна неприятная вещь - слишком маленький словарь. 1274 записей - это хороший показатель для игровой/книжной вселенной, но слишком мало для модели...\n",
    "\n",
    "В будущем можно запустить эту программу на более хорошей видеокарте и сделать больше сравнений с эталонными переводами, возможно метрики улучшатся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83575e7-60c1-4e54-9db7-3278775f429b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
