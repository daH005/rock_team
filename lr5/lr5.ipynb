{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24d3fc7-b458-4678-8e99-679b3ab533f8",
   "metadata": {},
   "source": [
    "В этой работе мы реализуем переводчик с русского языка на язык Старшей Речи и наоборот. Тоже самое с английским.\n",
    "Мы реализуем алгоритм для перевода с русского на Старшую Речь.\n",
    "Далее используем его для формирования примерно 200 эталонных переводов, на основе которых будем оценивать качество переводов следующих моделей:\n",
    "1. Llama\n",
    "2. Deepseek\n",
    "3. Gemma\n",
    "\n",
    "Перед началом переводов каждая модель будет настроена промптами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab7e4b1-0108-40b1-901b-940fb9fb1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "import pymorphy2\n",
    "lemmer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import ollama\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b4a420-c9a7-4fba-a953-c306550bd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../lr3/witcher_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b054f-52a3-4884-9a9b-b73d1c74bce8",
   "metadata": {},
   "source": [
    "Напишем прямой алгоритм перевода с русского на Старшую Речь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f271ebd5-0728-4dfd-9f5f-0e5a102c3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_russian_to_elvish(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Переводит русский текст на язык Старшей Речи.\n",
    "    Слова, перевод которым подобрать не получилось, латинизируются.\n",
    "    Присутствует обработка некоторых устойчивых выражений из словаря.\n",
    "    \"\"\"\n",
    "\n",
    "    # Унифицируем е/ё:\n",
    "    text = text.replace('ё', 'е')\n",
    "\n",
    "    # Результирующие подстроки для склеивания в конце.\n",
    "    result_subs = []\n",
    "\n",
    "    # Отделяем слова от пунктуационных знаков:\n",
    "    subs = re.split(r'(?<=\\.|!|\\?|,|;|:|\\s|\\n|\\(|\\))|(?=\\.|!|\\?|,|;|:|\\s|\\n|\\(|\\))', text)\n",
    "\n",
    "    next_i = 0\n",
    "    for i, sub in enumerate(subs):\n",
    "        if i < next_i:\n",
    "            continue\n",
    "\n",
    "        next_i += 1\n",
    "        if sub in string.punctuation + ' \\n':\n",
    "            result_subs.append(sub)\n",
    "            continue\n",
    "\n",
    "        word = sub\n",
    "        is_title = word.replace('\\'', '').istitle()\n",
    "        word = word.lower()\n",
    "        word = _word_to_lemm(word)\n",
    "\n",
    "        # Текущее слово может быть началом какого-то устойчивого выражения, проверим это.\n",
    "        it_is_real_phrase = False\n",
    "        phrases = _find_phrases_that_starts_with_russian_word(word)\n",
    "        if phrases and i != len(subs) - 1:\n",
    "            # Будем прибавлять сюда последующие пробелы и слова, пока не встретим что-то лишнее либо не убедимся\n",
    "            # в том, что это выражение - действительная устойчивая фраза из словаря.\n",
    "            summ_word = word\n",
    "\n",
    "            # Количество итераций для пропуска во внешнем цикле (через `next_i`)\n",
    "            count_to_pass = 0\n",
    "\n",
    "            for sub in subs[i + 1:]:\n",
    "                if sub in '.!?':\n",
    "                    break\n",
    "\n",
    "                count_to_pass += 1\n",
    "                if sub not in string.punctuation + ' ':\n",
    "                    sub = _word_to_lemm(sub.lower())\n",
    "                elif sub == ',':\n",
    "                    # Опускаем запятые между словами потенциальной фразы.\n",
    "                    sub = ''\n",
    "\n",
    "                summ_word += sub\n",
    "\n",
    "                need_continue = False\n",
    "                if summ_word in phrases:\n",
    "                    it_is_real_phrase = True\n",
    "                    break\n",
    "\n",
    "                for phrase in phrases:\n",
    "                    if summ_word in phrase:\n",
    "                        need_continue = True\n",
    "                        break\n",
    "\n",
    "                if not need_continue:\n",
    "                    break\n",
    "\n",
    "            if it_is_real_phrase:\n",
    "                word = summ_word\n",
    "                next_i += count_to_pass\n",
    "                translation = _try_to_find_russian_word_translation(word)\n",
    "\n",
    "        if not it_is_real_phrase:\n",
    "            # Стандартная обработка одиночного слова с подбором синонимов через сайт.\n",
    "            translation = _translate_russian_word(word, _synonyms_of_word_from_web_api)\n",
    "\n",
    "        if is_title:\n",
    "            translation = translation.capitalize()\n",
    "\n",
    "        result_subs.append(translation)\n",
    "\n",
    "    return ''.join(result_subs)\n",
    "\n",
    "\n",
    "def _word_to_lemm(word: str) -> str:\n",
    "    \"\"\"Переводит слово/словосочетание в начальную форму.\"\"\"\n",
    "    parts = []\n",
    "    for part in word.split():\n",
    "        part = lemmer.parse(part)[0].normal_form.replace('ё', 'е')\n",
    "        parts.append(part)\n",
    "\n",
    "    return ' '.join(parts)\n",
    "\n",
    "\n",
    "def _translate_russian_word(word: str, synonyms_finding_func) -> str:\n",
    "    \"\"\"\n",
    "    Переводит русское слово/словосочетание на Старшую Речь.\n",
    "    При отсутствии слова в датасете использует перебор синонимов из функции `synonyms_finding_func`.\n",
    "    Если последнее так же не помогло, то делает латинизацию слова.\n",
    "    \"\"\"\n",
    "    translation = None\n",
    "    try:\n",
    "        translation = _try_to_find_russian_word_translation(word)\n",
    "    except ValueError:\n",
    "        for synonym in _synonyms_of_word_from_web_api(word):\n",
    "            try:\n",
    "                translation = _try_to_find_russian_word_translation(synonym)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if translation is None:\n",
    "        translation = _transliterate_russian_to_latin(word)\n",
    "\n",
    "    return translation\n",
    "\n",
    "\n",
    "def _try_to_find_russian_word_translation(word: str) -> str:\n",
    "    \"\"\"Ищет перевод русского слова/словосочетания в датасете.\"\"\"\n",
    "    result = df.loc[df['translation'] == word, 'text']\n",
    "    if not result.empty:\n",
    "        return result.values[0]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def _find_phrases_that_starts_with_russian_word(word: str) -> list[str]:\n",
    "    return df.loc[df['translation'].str.startswith(word + ' '), 'translation'].tolist()\n",
    "\n",
    "\n",
    "def _synonyms_of_word_from_web_api(word: str) -> str:\n",
    "    \"\"\"Выдаёт всевозможные синонимы заданного слова. Использует сетевой запрос.\"\"\"\n",
    "    html = requests.get(f'https://text.ru/synonym/{word}').text\n",
    "    \n",
    "    match = re.search(r'<meta name=\\\"description\\\" content=\\\"Синонимы к слову [^—]*:([^\\\"]+)\\\" />', html)\n",
    "    if match is None:\n",
    "        return []\n",
    "\n",
    "    text = match.group(1)\n",
    "    synonyms = [synonym.strip() for synonym in text.strip().split('—')]\n",
    "    synonyms.remove('')\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "\n",
    "def _transliterate_russian_to_latin(russian_word: str) -> str:\n",
    "    \"\"\"Функция для латинизации русского слова.\"\"\"\n",
    "    translit_dict = {\n",
    "        'а': 'a', \n",
    "        'б': 'b', \n",
    "        'в': 'v', \n",
    "        'г': 'g', \n",
    "        'д': 'd', \n",
    "        'е': 'e', \n",
    "        'ё': 'yo',\n",
    "        'ж': 'zh', \n",
    "        'з': 'z', \n",
    "        'и': 'i', \n",
    "        'й': 'y', \n",
    "        'к': 'k', \n",
    "        'л': 'l', \n",
    "        'м': 'm',\n",
    "        'н': 'n', \n",
    "        'о': 'o', \n",
    "        'п': 'p', \n",
    "        'р': 'r', \n",
    "        'с': 's', \n",
    "        'т': 't', \n",
    "        'у': 'u',\n",
    "        'ф': 'f', \n",
    "        'х': 'kh', \n",
    "        'ц': 'ts', \n",
    "        'ч': 'ch', \n",
    "        'ш': 'sh', \n",
    "        'щ': 'shch', \n",
    "        'ъ': '',\n",
    "        'ы': 'y', \n",
    "        'ь': '', \n",
    "        'э': 'e', \n",
    "        'ю': 'yu', \n",
    "        'я': 'ya',\n",
    "    }\n",
    "\n",
    "    latin_word = ''.join(translit_dict.get(symbol, symbol) for symbol in russian_word.lower())\n",
    "    return latin_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b31f1-6b56-495c-8b41-419376cfdf4d",
   "metadata": {},
   "source": [
    "Посмотрим пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c6531b-60ec-4667-a1d3-be3311753b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cead, Geralt Gwynbleidd! Do prisutstvie - bolshiy aere а evellienn sinn.\n"
     ]
    }
   ],
   "source": [
    "print(translate_russian_to_elvish('Здравствуй, Геральт Белый Волк! Твоё присутствие - большая честь для всех нас.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94549c-4c3c-4402-be8e-dce8d18c1cb2",
   "metadata": {},
   "source": [
    "Сформируем списки эталонных переводов. Запускать следующую ячейку, если файла \"backup.json\" нет. Если есть, то вторую, после неё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba5ea00b-d766-46c4-8c7e-8d83086fb5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "with open('./sequences.txt', 'r', encoding='utf-8') as f:\n",
    "    i = 0\n",
    "    for record in f:\n",
    "        record = record.strip()\n",
    "        if not record:\n",
    "            continue\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            # Записываем русское предложение + перевод.\n",
    "            sequences.append([\n",
    "                record,\n",
    "                translate_russian_to_elvish(record),\n",
    "            ])\n",
    "        else:\n",
    "            # Дозаписываем соответствующее английское предложение.\n",
    "            sequences[-1].append(record)\n",
    "\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            print('Часть записей обработана.')\n",
    "\n",
    "# Сохраняем эталонные переводы, чтобы не проводить эту процедуру каждый раз.\n",
    "with open('backup.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sequences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5fb5db-639b-41d9-a1df-e33782a84141",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backup.json', 'r', encoding='utf-8') as f:\n",
    "    sequences = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704df4e-4bbf-42d1-b1c9-b2dd56853362",
   "metadata": {},
   "source": [
    "Рассмотрим модели LLM для решения задачи перевода. Напишем общий класс для всех наших моделей из Olama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af6e3873-ca3d-4d71-96ba-255d87dc8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    \"\"\"\n",
    "    Обёртка над моделью LLM из Olama для реализации перевода.\n",
    "    Реализованы двухсторонние переводы с русского/английского на Старшую речь.\n",
    "    Поступаемый текст сначала токенизируется, лемматизируется, потом происходит поиск используемых слов\n",
    "    по словарю.\n",
    "    После всего этого исходный текст (всегда русский либо эльфский) и собранная часть словаря отправляются модели.\n",
    "    Это ускорило обработку во много раз, поскольку изначально модели залился словарь целиком (это был этап \"инициализации\"),\n",
    "    а потом происходили переводы.\n",
    "    Здесь нам даже не нужно хранить историю предыдущих сообщений.\n",
    "    \"\"\"\n",
    "\n",
    "    _RESULT_LIMITER: str = 'RESULT'\n",
    "    _SYNONYM_SEPARATOR: str = ','\n",
    "\n",
    "    def __init__(self, model_name: str) -> None:\n",
    "        self._model_name = model_name\n",
    "\n",
    "    def translate_russian_to_elvish(self, text: str) -> str:\n",
    "        \"\"\"Переводит русский текст на Старшую Речь.\"\"\"\n",
    "        dictionary = self._make_dictionary_by_russian_text(text)\n",
    "        return self._request(f'Переведи русский текст \"{text}\" на другой язык согласно словарю:\\n' + dictionary)\n",
    "\n",
    "    def translate_elvish_to_russian(self, text: str) -> str:\n",
    "        \"\"\"Переводит текст на языке Старшей Речи на русский.\"\"\"\n",
    "        dictionary = self._make_dictionary_by_elvish_text(text)\n",
    "        return self._request(f'Переведи вымышленный текст \"{text}\" на русский согласно словарю:\\n' + dictionary)\n",
    "\n",
    "    def translate_english_to_elvish(self, text: str) -> str:\n",
    "        \"\"\"Переводит английский текст на Старшую Речь.\"\"\"\n",
    "        text = self._request(f'Переведи английский текст \"{text}\" на русский.')\n",
    "        return self.translate_russian_to_elvish(text)\n",
    "\n",
    "    def translate_elvish_to_english(self, text: str) -> str:\n",
    "        \"\"\"Переводит текст на языке Старшей Речи на английский.\"\"\"\n",
    "        text = self.translate_elvish_to_russian(text)\n",
    "        return self._request(f'Переведи русский текст \"{text}\" на английский.')\n",
    "\n",
    "    def _make_dictionary_by_russian_text(self, text: str) -> str:\n",
    "        \"\"\"Формирует текстовый словарь, опираясь на слова используемые в русском тексте.\"\"\"\n",
    "        dictionary: str = ''\n",
    "\n",
    "        words = self._extract_lemms(text)\n",
    "        for word in words:\n",
    "            dictionary += word + ' - ' + _translate_russian_word(word, self._synonyms_of_word) + '\\n'\n",
    "            for translation, phrase in self._russian_phrases_that_starts_with_word_and_translations(word):\n",
    "                dictionary += phrase + ' - ' + translation + '\\n'\n",
    "\n",
    "        return dictionary\n",
    "\n",
    "    def _make_dictionary_by_elvish_text(self, text: str) -> str:\n",
    "        \"\"\"Формирует текстовый словарь, опираясь на слова используемые в тексте на языке Старшей Речи.\"\"\"\n",
    "        dictionary: str = ''\n",
    "\n",
    "        words = self._extract_words(text)\n",
    "        for word in words:\n",
    "            for translation in self._elvish_word_translations(word):\n",
    "                dictionary += word + ' - ' + translation + '\\n'\n",
    "            for phrase, translation in self._elvish_phrases_that_starts_with_word_and_translations(word):\n",
    "                dictionary += phrase + ' - ' + translation + '\\n'\n",
    "\n",
    "        return dictionary\n",
    "\n",
    "    def _extract_lemms(self, text: str) -> list[str]:\n",
    "        \"\"\"Извлекает из текста слова и приводит их к начальной форме.\"\"\"\n",
    "        return [_word_to_lemm(word) for word in self._extract_words(text)]\n",
    "\n",
    "    def _extract_words(self, text: str) -> list[str]:\n",
    "        \"\"\"Извлекает из текста слова и переводит их в нижний регистр.\"\"\"\n",
    "        text = self._remove_punctuation(text)\n",
    "        return text.lower().split()\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_punctuation(text: str) -> str:\n",
    "        \"\"\"Удаляет из текста все знаки препинания и пунктуации.\"\"\"\n",
    "        return text.translate(\n",
    "            str.maketrans('', '', string.punctuation),\n",
    "        )\n",
    "\n",
    "    def _synonyms_of_word(self, word: str) -> list[str]:\n",
    "        \"\"\"Выдаёт синонимы слова, которые подобрала модель.\"\"\"\n",
    "        text = self._request(f'Подбери синонимы слова \"{word}\". Разделяй их через {self._SYNONYM_SEPARATOR}.')\n",
    "        return [word.strip() for word in text.split(self._SYNONYM_SEPARATOR)]\n",
    "\n",
    "    def _russian_phrases_that_starts_with_word_and_translations(self, word: str) -> list[tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Выдает все фразы и их переводы, которые начинаются с переданного русского слова.\n",
    "        Первое в каждом кортеже эльфское, второе - русское.\n",
    "        \"\"\"\n",
    "        return self._phrases_that_starts_with_word_and_translations(word, 'translation')\n",
    "\n",
    "    def _elvish_phrases_that_starts_with_word_and_translations(self, word: str) -> list[tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Выдает все фразы и их переводы, которые начинаются с переданного слова на Старшей Речи.\n",
    "        Первое в каждом кортеже эльфское, второе - русское.\n",
    "        \"\"\"\n",
    "        return self._phrases_that_starts_with_word_and_translations(word, 'text')\n",
    "\n",
    "    @staticmethod\n",
    "    def _phrases_that_starts_with_word_and_translations(word: str, col: str) -> list[tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Выдает все фразы и их переводы, которые начинаются с переданного слова в заданном столбце `df`.\n",
    "        Первое в каждом кортеже эльфское, второе - русское.\n",
    "        \"\"\"\n",
    "        return df[df[col].str.startswith(word + ' ')].itertuples(index=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def _elvish_word_translations(word: str) -> list[str]:\n",
    "        \"\"\"Выдает всевозможные переводы слова на Старшей Речи.\"\"\"\n",
    "        result = df.loc[df['text'] == word, 'translation']\n",
    "        return result.values\n",
    "\n",
    "    def _request(self, text: str, extract_result: bool = True) -> str:\n",
    "        \"\"\"Отправляет запрос модели и выдает ответ.\"\"\"\n",
    "        if extract_result:\n",
    "            text += f'\\nСлева и справа от результата напиши \"{self._RESULT_LIMITER}\". Больше ничего лишнего не пиши.'\n",
    "\n",
    "        answer = ollama.chat(model=self._model_name, messages=[{\n",
    "            'role': 'user', \n",
    "            'content': text,\n",
    "        }])['message']['content']\n",
    "\n",
    "        # DeepSeek thinking isn't needed :)\n",
    "        if '</think>' in answer:\n",
    "            answer = answer.split('</think>')[1]\n",
    "\n",
    "        answer = answer.split(self._RESULT_LIMITER)[1]\n",
    "        return answer.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b8e91-addf-4dd9-86a0-9fcf1cd52055",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d6704f8-2608-4c6d-b725-18e4e90afcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love cooking new food.\n"
     ]
    }
   ],
   "source": [
    "t = Translator('gemma3')\n",
    "print(t.translate_elvish_to_english('Aé lyubit gotovit noel ite.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f8d2b1-867d-4730-be38-12c7689b4736",
   "metadata": {},
   "source": [
    "Начнем тестировать наши модели. Используем метрику BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a13494e7-b2c9-42d3-90c8-c12718439b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_model(model_name: str) -> None:\n",
    "    print(model_name)\n",
    "    translator = Translator(model_name)\n",
    "\n",
    "    bleu_scores_russian_to_elvish = []\n",
    "    bleu_scores_elvish_to_russian = []\n",
    "\n",
    "    bleu_scores_english_to_elvish = []\n",
    "    bleu_scores_elvish_to_english = []\n",
    "\n",
    "    for i, record in enumerate(sequences, start=1):\n",
    "        if i % 50 == 0:\n",
    "            print('Часть записей обработана.')\n",
    "\n",
    "        try:\n",
    "            bleu_scores_russian_to_elvish.append(\n",
    "                sentence_bleu(\n",
    "                    translator.translate_russian_to_elvish(record[0]), \n",
    "                    record[1],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            bleu_scores_elvish_to_russian.append(\n",
    "                sentence_bleu(\n",
    "                    translator.translate_elvish_to_russian(record[1]), \n",
    "                    record[0],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            bleu_scores_english_to_elvish.append(\n",
    "                sentence_bleu(\n",
    "                    translator.translate_english_to_elvish(record[2]), \n",
    "                    record[1],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            bleu_scores_elvish_to_english.append(\n",
    "                sentence_bleu(\n",
    "                    translator.translate_elvish_to_english(record[1]), \n",
    "                    record[2],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    score = sum(bleu_scores_russian_to_elvish) / len(bleu_scores_russian_to_elvish)\n",
    "    print('Russian-To-Elvish Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_elvish_to_russian) / len(bleu_scores_elvish_to_russian)\n",
    "    print('Elvish-To-Russian Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_english_to_elvish) / len(bleu_scores_english_to_elvish)\n",
    "    print('English-To-Elvish Score:', score)\n",
    "\n",
    "    score = sum(bleu_scores_elvish_to_english) / len(bleu_scores_elvish_to_english)\n",
    "    print('Elvish-To-English Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "191464cb-6d53-4fb9-abb8-2347b17c5d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n",
      "('А',)\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "('S',)\n",
      "('S',)\n",
      "Часть записей обработана.\n",
      "Russian-To-Elvish Score: 1.4081319323328796e-231\n",
      "Elvish-To-Russian Score: 1.3979871551804934e-231\n",
      "English-To-Elvish Score: 1.3821330859369786e-231\n",
      "Elvish-To-English Score: 1.370886268179268e-231\n"
     ]
    }
   ],
   "source": [
    "_test_model('llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b27e2-1482-431b-9964-d554b9949774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-r1\n",
      "('M',)\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "('T',)\n",
      "('I',)\n"
     ]
    }
   ],
   "source": [
    "_test_model('deepseek-r1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c69552a3-bc7d-439c-845e-f1b476f642cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3\n",
      "('A',)\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "Часть записей обработана.\n",
      "('I',)\n",
      "Russian-To-Elvish Score: 1.3956151220093285e-231\n",
      "Elvish-To-Russian Score: 1.3790497055025017e-231\n",
      "English-To-Elvish Score: 1.3802689495482624e-231\n",
      "Elvish-To-English Score: 1.3533990972923734e-231\n"
     ]
    }
   ],
   "source": [
    "_test_model('gemma3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16920e36-15cf-42b9-96e4-0deb3fa8f1f7",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "llama3 работает лучше всего по метрикам и выдает неплохие ответы.\n",
    "deepseek-r1 работает очень медленно и выдаёт кривые ответы.\n",
    "gemma3 работает хуже по метрикам, чем llama3 (из-за того, что пропускает пунктуацию), но зато довольно быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80981691-1754-402a-a0fe-6b5ec360a3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
